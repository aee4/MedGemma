{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 13842792,
          "sourceType": "datasetVersion",
          "datasetId": 8816807
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Medgemma -eczema",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aee4/MedGemma/blob/main/scripts/Medgemma_eczema.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "53d2wpAaVyHQ"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "emmanueleyramagbetor_dataset_eczema_path = kagglehub.dataset_download('emmanueleyramagbetor/dataset-eczema')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "jnF-UpVtVyHU"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-24T16:32:59.149804Z",
          "iopub.execute_input": "2025-11-24T16:32:59.150072Z",
          "iopub.status.idle": "2025-11-24T16:35:11.877736Z",
          "shell.execute_reply.started": "2025-11-24T16:32:59.150051Z",
          "shell.execute_reply": "2025-11-24T16:35:11.876782Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "lFdmeXBdVyHW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import login\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-24T16:35:16.469855Z",
          "iopub.execute_input": "2025-11-24T16:35:16.470481Z",
          "iopub.status.idle": "2025-11-24T16:35:22.769857Z",
          "shell.execute_reply.started": "2025-11-24T16:35:16.470441Z",
          "shell.execute_reply": "2025-11-24T16:35:22.76905Z"
        },
        "id": "anGJiQgiVyHY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "login()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-24T16:35:25.978103Z",
          "iopub.execute_input": "2025-11-24T16:35:25.978868Z",
          "iopub.status.idle": "2025-11-24T16:35:25.994958Z",
          "shell.execute_reply.started": "2025-11-24T16:35:25.978843Z",
          "shell.execute_reply": "2025-11-24T16:35:25.994108Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "fRpolL-HVyHZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from peft import LoraConfig\n",
        "from datasets import load_dataset\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-24T16:35:32.875814Z",
          "iopub.execute_input": "2025-11-24T16:35:32.876558Z",
          "iopub.status.idle": "2025-11-24T16:36:16.154564Z",
          "shell.execute_reply.started": "2025-11-24T16:35:32.876527Z",
          "shell.execute_reply": "2025-11-24T16:36:16.153672Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "HmZL5AVUVyHa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data_files = {\n",
        "    \"train\": \"/kaggle/input/dataset-eczema/train.csv\",\n",
        "    \"validation\": \"/kaggle/input/dataset-eczema/validation.csv\",\n",
        "    \"test\": \"/kaggle/input/dataset-eczema/test.csv\",\n",
        "}\n",
        "\n",
        "dataset = load_dataset(\"csv\", data_files=data_files)\n",
        "print(dataset)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-24T16:36:20.906049Z",
          "iopub.execute_input": "2025-11-24T16:36:20.90666Z",
          "iopub.status.idle": "2025-11-24T16:36:21.331778Z",
          "shell.execute_reply.started": "2025-11-24T16:36:20.906632Z",
          "shell.execute_reply": "2025-11-24T16:36:21.331138Z"
        },
        "id": "VMvPBA5LVyHa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def format_example(example):\n",
        "    text = example[\"text\"]\n",
        "    label = str(example[\"label\"])     # ensure \"0\" or \"1\"\n",
        "\n",
        "    example[\"messages\"] = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": f\"Description: {text}\\n\\nAnswer the correct class (0 or 1).\"}\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [{\"type\": \"text\", \"text\": label}]\n",
        "        }\n",
        "    ]\n",
        "    return example\n",
        "\n",
        "formatted_data = dataset.map(format_example)\n",
        "formatted_data\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-24T16:36:26.585302Z",
          "iopub.execute_input": "2025-11-24T16:36:26.585678Z",
          "iopub.status.idle": "2025-11-24T16:36:26.998673Z",
          "shell.execute_reply.started": "2025-11-24T16:36:26.585653Z",
          "shell.execute_reply": "2025-11-24T16:36:26.997829Z"
        },
        "id": "oo7l2nOcVyHa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"google/medgemma-4b-it\"\n",
        "\n",
        "model, processor = FastLanguageModel.from_pretrained(\n",
        "    model_name = model_id,\n",
        "    max_seq_length = 2048,\n",
        "    dtype = None,\n",
        "    load_in_4bit = True,\n",
        ")\n",
        "\n",
        "processor.tokenizer.padding_side = \"right\"\n",
        "print(\"Loaded MedGemma 4B IT with Unsloth.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-24T16:36:31.044016Z",
          "iopub.execute_input": "2025-11-24T16:36:31.044636Z",
          "iopub.status.idle": "2025-11-24T16:37:02.837167Z",
          "shell.execute_reply.started": "2025-11-24T16:36:31.04461Z",
          "shell.execute_reply": "2025-11-24T16:37:02.836529Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "cpH6dYmEVyHb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0.05,\n",
        "    bias = \"none\",\n",
        "    target_modules = \"all-linear\",\n",
        "    use_gradient_checkpointing = True,\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-24T16:37:48.297734Z",
          "iopub.execute_input": "2025-11-24T16:37:48.298478Z",
          "iopub.status.idle": "2025-11-24T16:37:53.443995Z",
          "shell.execute_reply.started": "2025-11-24T16:37:48.298447Z",
          "shell.execute_reply": "2025-11-24T16:37:53.443315Z"
        },
        "id": "_2kSDpnoVyHb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    texts = [\n",
        "        processor.apply_chat_template(\n",
        "            ex[\"messages\"],\n",
        "            add_generation_prompt=False,\n",
        "            tokenize=False\n",
        "        )\n",
        "        for ex in batch\n",
        "    ]\n",
        "\n",
        "    batch_inputs = processor(\n",
        "        text=texts,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True\n",
        "    )\n",
        "\n",
        "    labels = batch_inputs[\"input_ids\"].clone()\n",
        "    labels[labels == processor.tokenizer.pad_token_id] = -100\n",
        "    batch_inputs[\"labels\"] = labels\n",
        "\n",
        "    return batch_inputs\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-24T16:37:56.113352Z",
          "iopub.execute_input": "2025-11-24T16:37:56.11397Z",
          "iopub.status.idle": "2025-11-24T16:37:56.118953Z",
          "shell.execute_reply.started": "2025-11-24T16:37:56.113945Z",
          "shell.execute_reply": "2025-11-24T16:37:56.118104Z"
        },
        "id": "VUF-2iq8VyHc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def to_text(example):\n",
        "    return {\n",
        "        \"text\": processor.apply_chat_template(\n",
        "            example[\"messages\"],\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=False\n",
        "        )\n",
        "    }\n",
        "\n",
        "final_dataset = formatted_data.map(to_text, remove_columns=[\"messages\"])\n",
        "print(\"Example:\\n\", final_dataset[\"train\"][0][\"text\"])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-24T16:37:59.972345Z",
          "iopub.execute_input": "2025-11-24T16:37:59.972947Z",
          "iopub.status.idle": "2025-11-24T16:38:02.41262Z",
          "shell.execute_reply.started": "2025-11-24T16:37:59.972922Z",
          "shell.execute_reply": "2025-11-24T16:38:02.411768Z"
        },
        "id": "8hcIXcaGVyHc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTConfig\n",
        "\n",
        "args = SFTConfig(\n",
        "    output_dir=\"medgemma-binary-classification\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=2,\n",
        "    warmup_steps=5,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "    logging_steps=10,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=1,\n",
        "    seed=42,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=final_dataset[\"train\"],\n",
        "    eval_dataset=final_dataset[\"validation\"],\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=1024,\n",
        "    dataset_num_proc=1,\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-24T16:38:06.47087Z",
          "iopub.execute_input": "2025-11-24T16:38:06.471152Z",
          "iopub.status.idle": "2025-11-24T16:38:30.637706Z",
          "shell.execute_reply.started": "2025-11-24T16:38:06.47113Z",
          "shell.execute_reply": "2025-11-24T16:38:30.636744Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "Zimv524gVyHd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-24T16:38:36.994996Z",
          "iopub.execute_input": "2025-11-24T16:38:36.995578Z",
          "iopub.status.idle": "2025-11-24T18:41:53.798556Z",
          "shell.execute_reply.started": "2025-11-24T16:38:36.995545Z",
          "shell.execute_reply": "2025-11-24T18:41:53.797902Z"
        },
        "id": "k8kvYEAQVyHd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = trainer.evaluate()\n",
        "print(eval_results)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-24T18:44:03.383225Z",
          "iopub.execute_input": "2025-11-24T18:44:03.384518Z",
          "iopub.status.idle": "2025-11-24T18:46:45.16222Z",
          "shell.execute_reply.started": "2025-11-24T18:44:03.384464Z",
          "shell.execute_reply": "2025-11-24T18:46:45.161548Z"
        },
        "id": "vgIES_b3VyHd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-24T18:59:21.295182Z",
          "iopub.execute_input": "2025-11-24T18:59:21.295962Z",
          "iopub.status.idle": "2025-11-24T18:59:24.68063Z",
          "shell.execute_reply.started": "2025-11-24T18:59:21.295933Z",
          "shell.execute_reply": "2025-11-24T18:59:24.679825Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "uVi76DN4VyHd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Folder to save your model\n",
        "save_path = \"/kaggle/working/my_model\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Save the LoRA-finetuned model (instance method)\n",
        "model.save_pretrained(save_path)\n",
        "\n",
        "# Save the tokenizer\n",
        "processor.tokenizer.save_pretrained(save_path)\n",
        "\n",
        "print(f\"Model and tokenizer saved to {save_path}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-24T19:15:23.569472Z",
          "iopub.execute_input": "2025-11-24T19:15:23.569789Z",
          "iopub.status.idle": "2025-11-24T19:15:24.782678Z",
          "shell.execute_reply.started": "2025-11-24T19:15:23.569769Z",
          "shell.execute_reply": "2025-11-24T19:15:24.781804Z"
        },
        "id": "vD2qe-aWVyHd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi\n",
        "\n",
        "repo_id = \"aee4/medgemma-eczema\"\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "api.create_repo(repo_id=repo_id, private=False)\n",
        "\n",
        "api.upload_folder(\n",
        "    folder_path=\"/kaggle/working/my_model\",\n",
        "    repo_id=repo_id,\n",
        "    commit_message=\"Upload fine-tuned model\"\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-24T19:16:19.950695Z",
          "iopub.execute_input": "2025-11-24T19:16:19.950966Z",
          "iopub.status.idle": "2025-11-24T19:16:25.394809Z",
          "shell.execute_reply.started": "2025-11-24T19:16:19.950947Z",
          "shell.execute_reply": "2025-11-24T19:16:25.394Z"
        },
        "id": "2GNoWUglVyHd"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}