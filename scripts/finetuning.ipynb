{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 13698847,
          "sourceType": "datasetVersion",
          "datasetId": 8713855
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "finetuning",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aee4/MedGemma/blob/main/scripts/finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "L3hwLAqh9yM9"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "emmanueleyramagbetor_text_dataset_path = kagglehub.dataset_download('emmanueleyramagbetor/text-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "xhEKnoa19yM-"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"unsloth[colab-new]\" torch datasets trl transformers peft accelerate bitsandbytes\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T19:20:15.760943Z",
          "iopub.execute_input": "2025-11-13T19:20:15.761159Z",
          "iopub.status.idle": "2025-11-13T19:24:47.411328Z",
          "shell.execute_reply.started": "2025-11-13T19:20:15.761131Z",
          "shell.execute_reply": "2025-11-13T19:24:47.410331Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "R4TJ7PcH9yM_",
        "outputId": "8e3b73ec-a53e-4062-fda9-7152834f9912"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.4.1)\nCollecting trl\n  Downloading trl-0.25.1-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nRequirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.16.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nCollecting unsloth[colab-new]\n  Downloading unsloth-2025.11.2-py3-none-any.whl.metadata (61 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.8/61.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting unsloth_zoo>=2025.11.3 (from unsloth[colab-new])\n  Downloading unsloth_zoo-2025.11.3-py3-none-any.whl.metadata (32 kB)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.45.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (25.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.21.0+cu124)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (1.26.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (7.1.3)\nCollecting tyro (from unsloth[colab-new])\n  Downloading tyro-0.9.35-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (6.33.0)\nCollecting xformers>=0.0.27.post2 (from unsloth[colab-new])\n  Downloading xformers-0.0.33-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (3.2.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.2.0)\nCollecting datasets\n  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.36.0)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.34.0)\nCollecting trl\n  Downloading trl-0.23.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nCollecting pyarrow>=21.0.0 (from datasets)\n  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.5)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.6.0)\nCollecting multiprocess<0.70.17 (from datasets)\n  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\nCollecting fsspec (from torch)\n  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.3)\nCollecting transformers\n  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\nCollecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth[colab-new]) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth[colab-new]) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth[colab-new]) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth[colab-new]) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth[colab-new]) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth[colab-new]) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth[colab-new]) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\nCollecting torchao>=0.13.0 (from unsloth_zoo>=2025.11.3->unsloth[colab-new])\n  Downloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (19 kB)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.11.3->unsloth[colab-new])\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.11.3->unsloth[colab-new]) (11.3.0)\nCollecting msgspec (from unsloth_zoo>=2025.11.3->unsloth[colab-new])\n  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\nCollecting torch\n  Downloading torch-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\nCollecting sympy>=1.13.3 (from torch)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.1.0.70->torch)\n  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-curand-cu12==10.3.9.90 (from torch)\n  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch)\n  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\nCollecting nvidia-nccl-cu12==2.27.5 (from torch)\n  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\nCollecting nvidia-nvtx-cu12==12.8.90 (from torch)\n  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch)\n  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting triton>=3.0.0 (from unsloth[colab-new])\n  Downloading triton-3.5.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth[colab-new]) (8.7.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision (from unsloth[colab-new])\n  Downloading torchvision-0.24.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n  Downloading torchvision-0.24.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth[colab-new]) (0.17.0)\nRequirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth[colab-new]) (14.2.0)\nCollecting shtab>=1.5.6 (from tyro->unsloth[colab-new])\n  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth[colab-new]) (4.4.4)\n\u001b[33mWARNING: unsloth 2025.11.2 does not provide the extra 'triton'\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]) (2.19.2)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers->unsloth[colab-new]) (3.23.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth[colab-new]) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth[colab-new]) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth[colab-new]) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->unsloth[colab-new]) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->unsloth[colab-new]) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->unsloth[colab-new]) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[colab-new]) (0.1.2)\nDownloading datasets-4.3.0-py3-none-any.whl (506 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading trl-0.23.0-py3-none-any.whl (564 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m564.7/564.7 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.11.3-py3-none-any.whl (278 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.33-cp39-abi3-manylinux_2_28_x86_64.whl (121.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.8/121.8 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl (899.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m977.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.5.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.4/170.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.24.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.9.35-py3-none-any.whl (132 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading unsloth-2025.11.2-py3-none-any.whl (351 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m351.3/351.3 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\nDownloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (7.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torchao, nvidia-cusparselt-cu12, triton, sympy, shtab, pyarrow, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, multiprocess, msgspec, fsspec, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, tyro, tokenizers, nvidia-cusolver-cu12, torch, cut_cross_entropy, transformers, datasets, trl, xformers, unsloth_zoo, torchvision, bitsandbytes, unsloth\n  Attempting uninstall: torchao\n    Found existing installation: torchao 0.10.0\n    Uninstalling torchao-0.10.0:\n      Successfully uninstalled torchao-0.10.0\n  Attempting uninstall: nvidia-cusparselt-cu12\n    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.18\n    Uninstalling multiprocess-0.70.18:\n      Successfully uninstalled multiprocess-0.70.18\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.10.0\n    Uninstalling fsspec-2025.10.0:\n      Successfully uninstalled fsspec-2025.10.0\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.53.3\n    Uninstalling transformers-4.53.3:\n      Successfully uninstalled transformers-4.53.3\n  Attempting uninstall: datasets\n    Found existing installation: datasets 4.4.1\n    Uninstalling datasets-4.4.1:\n      Successfully uninstalled datasets-4.4.1\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.21.0+cu124\n    Uninstalling torchvision-0.21.0+cu124:\n      Successfully uninstalled torchvision-0.21.0+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ns3fs 2025.3.0 requires fsspec==2025.3.0.*, but you have fsspec 2025.9.0 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.9.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.48.2 cut_cross_entropy-25.1.1 datasets-4.3.0 fsspec-2025.9.0 msgspec-0.19.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 pyarrow-22.0.0 shtab-1.7.2 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.0 torchao-0.14.1 torchvision-0.24.0 transformers-4.57.1 triton-3.5.0 trl-0.23.0 tyro-0.9.35 unsloth-2025.11.2 unsloth_zoo-2025.11.3 xformers-0.0.33\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from huggingface_hub import login\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T19:25:20.707791Z",
          "iopub.execute_input": "2025-11-13T19:25:20.708136Z",
          "iopub.status.idle": "2025-11-13T19:25:23.884406Z",
          "shell.execute_reply.started": "2025-11-13T19:25:20.708103Z",
          "shell.execute_reply": "2025-11-13T19:25:23.883817Z"
        },
        "id": "IJkVpfdn9yM_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "login()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T19:25:33.95766Z",
          "iopub.execute_input": "2025-11-13T19:25:33.95855Z",
          "iopub.status.idle": "2025-11-13T19:25:33.973975Z",
          "shell.execute_reply.started": "2025-11-13T19:25:33.958522Z",
          "shell.execute_reply": "2025-11-13T19:25:33.973168Z"
        },
        "id": "5KjL2ntW9yNA",
        "outputId": "cf7fe017-a423-4f23-fe0e-dc586358ddb7",
        "colab": {
          "referenced_widgets": [
            "3a14522df0b048819b95e42f53b49a38"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a14522df0b048819b95e42f53b49a38"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "from trl import SFTTrainer\n",
        "from transformers import AutoProcessor\n",
        "from peft import LoraConfig\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T19:25:42.266057Z",
          "iopub.execute_input": "2025-11-13T19:25:42.266748Z",
          "iopub.status.idle": "2025-11-13T19:26:16.121073Z",
          "shell.execute_reply.started": "2025-11-13T19:25:42.266713Z",
          "shell.execute_reply": "2025-11-13T19:26:16.120249Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "RR-k9cHY9yNA",
        "outputId": "92e7344b-8671-40a1-de16-69e00db8ae45"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2025-11-13 19:25:45.861106: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763061946.029683      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763061946.076687      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n[xformers|WARNING]WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n    PyTorch 2.9.0+cu130 with CUDA 1300 (you have 2.9.0+cu128)\n    Python  3.10.19 (you have 3.11.13)\n  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n  Set XFORMERS_MORE_DETAILS=1 for more details\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "========\nSwitching to PyTorch attention since your Xformers is broken.\n========\n\nUnsloth: Xformers was not installed correctly.\nPlease install xformers separately first.\nThen confirm if it's correctly installed by running:\npython -m xformers.info\n\nLonger error message:\nxFormers can't load C++/CUDA extensions. xFormers was built for:\n    PyTorch 2.9.0+cu130 with CUDA 1300 (you have 2.9.0+cu128)\n    Python  3.10.19 (you have 3.11.13)\n  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n  Memory-efficient attention, SwiGLU, sparse and more won't be available.\nğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv(\"/kaggle/input/text-dataset/train.csv\")\n",
        "test = pd.read_csv(\"/kaggle/input/text-dataset/test.csv\")\n",
        "validation = pd.read_csv(\"/kaggle/input/text-dataset/validation.csv\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T19:26:44.114296Z",
          "iopub.execute_input": "2025-11-13T19:26:44.114606Z",
          "iopub.status.idle": "2025-11-13T19:26:44.181364Z",
          "shell.execute_reply.started": "2025-11-13T19:26:44.114584Z",
          "shell.execute_reply": "2025-11-13T19:26:44.180483Z"
        },
        "id": "A075B7gU9yNA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "import torch\n",
        "\n",
        "# Load your CSVs\n",
        "data_files = {\n",
        "    \"train\": \"/kaggle/input/text-dataset/train.csv\",\n",
        "    \"validation\": \"/kaggle/input/text-dataset/validation.csv\",\n",
        "    \"test\": \"/kaggle/input/text-dataset/test.csv\",\n",
        "}\n",
        "dataset = load_dataset(\"csv\", data_files=data_files)\n",
        "\n",
        "# Inspect\n",
        "print(dataset)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T19:26:46.775912Z",
          "iopub.execute_input": "2025-11-13T19:26:46.776192Z",
          "iopub.status.idle": "2025-11-13T19:26:47.582454Z",
          "shell.execute_reply.started": "2025-11-13T19:26:46.77617Z",
          "shell.execute_reply": "2025-11-13T19:26:47.581665Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "collapsed": true,
        "id": "3XIXeamD9yNA",
        "outputId": "c480a816-5a6f-4086-b5d3-a04dd308e5c7",
        "colab": {
          "referenced_widgets": [
            "b59e97deb3004e7e8cf21ea4deb64c71",
            "55c8c5ada7c84e6db36ac0eb78b4aa59",
            "554f3d42c93446eca001c5e82b7b3b15"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b59e97deb3004e7e8cf21ea4deb64c71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating validation split: 0 examples [00:00, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55c8c5ada7c84e6db36ac0eb78b4aa59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "554f3d42c93446eca001c5e82b7b3b15"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "DatasetDict({\n    train: Dataset({\n        features: ['disease', 'text', 'label'],\n        num_rows: 3000\n    })\n    validation: Dataset({\n        features: ['disease', 'text', 'label'],\n        num_rows: 2000\n    })\n    test: Dataset({\n        features: ['disease', 'text', 'label'],\n        num_rows: 2000\n    })\n})\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#  Extract unique label names safely\n",
        "label_values = sorted(list(set(dataset['train']['label'])))\n",
        "formatted_classes = [f\"{chr(65 + i)}: {label}\" for i, label in enumerate(label_values)]\n",
        "\n",
        "# Create the prompt for text classification\n",
        "options = \"\\n\".join(formatted_classes)\n",
        "PROMPT = f\"What is the most likely skin disease described in the text?\\n{options}\"\n",
        "\n",
        "# ğŸ’¬ Format function for text classification\n",
        "def format_data(example: dict) -> dict:\n",
        "    label_value = example[\"label\"]\n",
        "    example[\"messages\"] = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [{\"type\": \"text\", \"text\": f\"{PROMPT}\\n\\nDescription: {example['text']}\"}],\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [{\"type\": \"text\", \"text\": str(label_value)}],\n",
        "        },\n",
        "    ]\n",
        "    return example\n",
        "\n",
        "# ğŸ§  Apply formatting to all splits\n",
        "formatted_data = dataset.map(format_data, remove_columns=[\"label\"])\n",
        "\n",
        "print(\"\\nâœ… Dataset is formatted for training.\")\n",
        "formatted_data"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T19:27:03.550499Z",
          "iopub.execute_input": "2025-11-13T19:27:03.551278Z",
          "iopub.status.idle": "2025-11-13T19:27:04.055869Z",
          "shell.execute_reply.started": "2025-11-13T19:27:03.551241Z",
          "shell.execute_reply": "2025-11-13T19:27:04.055062Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "collapsed": true,
        "id": "GHIhSYQP9yNB",
        "outputId": "1d1ccc63-ae51-4455-e8aa-d6ec3bd7df37",
        "colab": {
          "referenced_widgets": [
            "2dde795ac95a45e7acd8cf96edcc93e1",
            "b8233ceb7c1a41ce9d9db356f8c9257d",
            "e964b32656cb41d5b12c6b5c97a8f4c6"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2dde795ac95a45e7acd8cf96edcc93e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8233ceb7c1a41ce9d9db356f8c9257d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e964b32656cb41d5b12c6b5c97a8f4c6"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\nâœ… Dataset is formatted for training.\n",
          "output_type": "stream"
        },
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['disease', 'text', 'messages'],\n        num_rows: 3000\n    })\n    validation: Dataset({\n        features: ['disease', 'text', 'messages'],\n        num_rows: 2000\n    })\n    test: Dataset({\n        features: ['disease', 'text', 'messages'],\n        num_rows: 2000\n    })\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"google/medgemma-4b-it\"\n",
        "model, processor = FastLanguageModel.from_pretrained(\n",
        "    model_name=model_id,\n",
        "    max_seq_length=2048,\n",
        "    dtype=None,             # Unsloth handles dtype automatically\n",
        "    load_in_4bit=True,      # This enables 4-bit quantization\n",
        ")\n",
        "processor.tokenizer.padding_side = \"right\"\n",
        "print(\"Model loaded with Unsloth optimizations.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T19:27:10.65905Z",
          "iopub.execute_input": "2025-11-13T19:27:10.659802Z",
          "iopub.status.idle": "2025-11-13T19:28:08.509372Z",
          "shell.execute_reply.started": "2025-11-13T19:27:10.659754Z",
          "shell.execute_reply": "2025-11-13T19:28:08.508512Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "CaAac4rY9yNB",
        "outputId": "a832e4b1-3b0b-4656-a672-d5ab9f89debf",
        "colab": {
          "referenced_widgets": [
            "ac88e232814b4d80b6426d27af89163d",
            "cf51dd0dcd91495bb92c773ae6f9792e",
            "0b865caab3de470aa7549e857aa9ff41",
            "56ab13ba32b545a5b40d4ebf46f7fe88",
            "5bf65dad74e44e4e9a11ff2329795856",
            "393636c1326d49199564710dc80c7cd7",
            "7a800d9000e74401a37600837acdc6e9",
            "4fd4e8250ef749ad826044f2786dde67",
            "5941fb98bdd64970bae71c3d486cdbe4",
            "f4c69451ddf2450c9a388462a5fb4df0"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "==((====))==  Unsloth 2025.11.2: Fast Gemma3 patching. Transformers: 4.57.1.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.9.0+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\nUnsloth: Using float16 precision for gemma3 won't work! Using float32.\nUnsloth: Gemma3 does not support SDPA - switching to fast eager.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/4.12G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac88e232814b4d80b6426d27af89163d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/210 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf51dd0dcd91495bb92c773ae6f9792e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "processor_config.json:   0%|          | 0.00/70.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b865caab3de470aa7549e857aa9ff41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "chat_template.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56ab13ba32b545a5b40d4ebf46f7fe88"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "preprocessor_config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bf65dad74e44e4e9a11ff2329795856"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "393636c1326d49199564710dc80c7cd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a800d9000e74401a37600837acdc6e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fd4e8250ef749ad826044f2786dde67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5941fb98bdd64970bae71c3d486cdbe4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/670 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4c69451ddf2450c9a388462a5fb4df0"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Model loaded with Unsloth optimizations.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    target_modules=\"all-linear\",\n",
        "    use_gradient_checkpointing=True,\n",
        ")\n",
        "\n",
        "def collate_fn(examples: list[dict]):\n",
        "    images = [example['image'] for example in examples]\n",
        "    texts = [\n",
        "        processor.apply_chat_template(ex['messages'], add_generation_prompt=False, tokenize=False).strip()\n",
        "        for ex in examples\n",
        "    ]\n",
        "    batch = processor(text=texts, images=images, return_tensors=\"pt\", padding=True)\n",
        "    labels = batch['input_ids'].clone()\n",
        "    labels[labels == processor.tokenizer.pad_token_id] = -100\n",
        "    batch[\"labels\"] = labels\n",
        "    return batch"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T19:28:25.104007Z",
          "iopub.execute_input": "2025-11-13T19:28:25.104935Z",
          "iopub.status.idle": "2025-11-13T19:28:30.478202Z",
          "shell.execute_reply.started": "2025-11-13T19:28:25.104909Z",
          "shell.execute_reply": "2025-11-13T19:28:30.477199Z"
        },
        "id": "qNhQIw6T9yNB",
        "outputId": "1b6458fc-bcfe-4422-f950-f4e6fafc6b60"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\nUnsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Unsloth: Making `base_model.model.model.vision_tower.vision_model` require gradients\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer, SFTConfig\n",
        "import torch"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T19:28:42.101747Z",
          "iopub.execute_input": "2025-11-13T19:28:42.102088Z",
          "iopub.status.idle": "2025-11-13T19:28:42.106042Z",
          "shell.execute_reply.started": "2025-11-13T19:28:42.102065Z",
          "shell.execute_reply": "2025-11-13T19:28:42.105343Z"
        },
        "id": "nh4q3gYM9yNB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 1ï¸âƒ£ Define the formatting function\n",
        "def format_dataset_for_unsloth(example):\n",
        "    text = processor.apply_chat_template(\n",
        "        example[\"messages\"],\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=False\n",
        "    )\n",
        "    return {\"text\": text}\n",
        "\n",
        "\n",
        "# 2ï¸âƒ£ Format the entire dataset (keep num_proc=1 for safety)\n",
        "preformatted_dataset = formatted_data.map(\n",
        "    format_dataset_for_unsloth,\n",
        "    num_proc=1\n",
        ")\n",
        "\n",
        "print(\"âœ… Dataset pre-formatted with a 'text' column.\")\n",
        "print(\"Example entry:\\n\", preformatted_dataset[\"train\"][0][\"text\"])\n",
        "\n",
        "\n",
        "# 3ï¸âƒ£ Define training arguments â€” optimized for Colab\n",
        "args = SFTConfig(\n",
        "    output_dir=\"medgemma-unsloth\",\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=2,     # balances speed & stability\n",
        "    warmup_steps=5,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,                         # mixed precision for memory efficiency\n",
        "    logging_steps=10,\n",
        "    optim=\"adamw_torch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_total_limit=1,\n",
        "    seed=42,\n",
        "    report_to=\"none\",                  # disable wandb\n",
        ")\n",
        "\n",
        "\n",
        "# 4ï¸âƒ£ Prepare train/validation splits\n",
        "train_data = preformatted_dataset[\"train\"]\n",
        "val_data = preformatted_dataset[\"validation\"]\n",
        "\n",
        "\n",
        "# 5ï¸âƒ£ Initialize the trainer with reduced sequence length\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=1024,               # lower seq length = less memory\n",
        "    dataset_num_proc=1,\n",
        "    args=args,\n",
        ")\n",
        "\n",
        "print(\"ğŸš€ Trainer ready. Training for 3 epochs with evaluation after each epoch.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T19:28:44.989301Z",
          "iopub.execute_input": "2025-11-13T19:28:44.99Z",
          "iopub.status.idle": "2025-11-13T19:29:15.711858Z",
          "shell.execute_reply.started": "2025-11-13T19:28:44.989964Z",
          "shell.execute_reply": "2025-11-13T19:29:15.711143Z"
        },
        "id": "duorEOuO9yNB",
        "outputId": "c367c9e6-2023-4d2f-b710-3efe58005261",
        "colab": {
          "referenced_widgets": [
            "deb1caee8df749f5bd42fe07c5d849c5",
            "7ba27330be2e4e028e782ce816d9c4f1",
            "7b2a2f7594934a6188ff2bebe40265d8",
            "bbd46b99259c4f9690ed675cb790cd85",
            "6011a91e57b4444cae16d43b357ade47"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map (num_proc=1):   0%|          | 0/3000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "deb1caee8df749f5bd42fe07c5d849c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map (num_proc=1):   0%|          | 0/2000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ba27330be2e4e028e782ce816d9c4f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map (num_proc=1):   0%|          | 0/2000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b2a2f7594934a6188ff2bebe40265d8"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "âœ… Dataset pre-formatted with a 'text' column.\nExample entry:\n <bos><start_of_turn>user\nWhat is the most likely skin disease described in the text?\nA: 0\nB: 1\n\nDescription: Blistering or weeping lesions in acute flares appearing in skin creases and folds. The patient feels unbearably itchy, especially at night and describes the disease as mild and intermittent. Sometimes flares after infections or insect bites.<end_of_turn>\n<start_of_turn>model\n1<end_of_turn>\n\nUnsloth: Switching to float32 training since model cannot work with float16\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Unsloth: Tokenizing [\"text\"] (num_proc=8):   0%|          | 0/3000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbd46b99259c4f9690ed675cb790cd85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Unsloth: Tokenizing [\"text\"] (num_proc=8):   0%|          | 0/2000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6011a91e57b4444cae16d43b357ade47"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "ğŸš€ Trainer ready. Training for 3 epochs with evaluation after each epoch.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T19:29:22.912325Z",
          "iopub.execute_input": "2025-11-13T19:29:22.913001Z",
          "iopub.status.idle": "2025-11-14T01:10:52.748436Z",
          "shell.execute_reply.started": "2025-11-13T19:29:22.912971Z",
          "shell.execute_reply": "2025-11-14T01:10:52.747764Z"
        },
        "id": "clvrfWZ39yNC",
        "outputId": "709786c1-0d1b-4de4-8fc1-b3ed97c4e784"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 3,000 | Num Epochs = 10 | Total steps = 15,000\nO^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 2\n\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 2 x 1) = 2\n \"-____-\"     Trainable parameters = 38,497,792 of 4,338,577,264 (0.89% trained)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='15000' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [15000/15000 5:40:19, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.087000</td>\n      <td>0.170258</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.087700</td>\n      <td>0.169756</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.085500</td>\n      <td>0.166481</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.088300</td>\n      <td>0.162906</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.085500</td>\n      <td>0.164516</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.082900</td>\n      <td>0.167111</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.082400</td>\n      <td>0.165915</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.081800</td>\n      <td>0.162073</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.077400</td>\n      <td>0.162008</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.075800</td>\n      <td>0.157538</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Unsloth: Not an error, but Gemma3ForConditionalGeneration does not accept `num_items_in_batch`.\nUsing gradient accumulation will be very slightly less accurate.\nRead more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n",
          "output_type": "stream"
        },
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainOutput(global_step=15000, training_loss=0.0860549313823382, metrics={'train_runtime': 20487.4306, 'train_samples_per_second': 1.464, 'train_steps_per_second': 0.732, 'total_flos': 4.78541474621952e+16, 'train_loss': 0.0860549313823382, 'epoch': 10.0})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "1mJfqhkD9yNC"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}